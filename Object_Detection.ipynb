{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "https://github.com/Gautam-Chauhan/Code/blob/main/Object_Detection.ipynb",
      "authorship_tag": "ABX9TyMkcIIm7SsyNTAlO+35PAnV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Gautam-Chauhan/MAPS-Internship-Code/blob/main/Object_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Object Detection Notebook"
      ],
      "metadata": {
        "id": "TV80nxGjXz73"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this notebook, we will fine-tune a pre-trained model for object detection with the TensorFlow Object Detection API.\n",
        "\n",
        "This notebook will closely follow the official TensorFlow Object Detection Tutorial: https://tensorflow-object-detection-api-tutorial.readthedocs.io/en/latest/training.html#"
      ],
      "metadata": {
        "id": "tyT-ThjZYBMM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before starting, run the following cell to change the versions of certain installed packages:"
      ],
      "metadata": {
        "id": "rvYzwynuKrom"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall tensorflow -y\n",
        "!pip install tensorflow==2.15.1"
      ],
      "metadata": {
        "id": "LFImQV_-KqS7",
        "outputId": "7aa9553d-0091-460e-dfa3-0579878fb79b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: tensorflow 2.18.0\n",
            "Uninstalling tensorflow-2.18.0:\n",
            "  Successfully uninstalled tensorflow-2.18.0\n",
            "Collecting tensorflow==2.15.1\n",
            "  Downloading tensorflow-2.15.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.1) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.1) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.1) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.1) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.1) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.1) (3.14.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.1) (18.1.1)\n",
            "Collecting ml-dtypes~=0.3.1 (from tensorflow==2.15.1)\n",
            "  Downloading ml_dtypes-0.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Collecting numpy<2.0.0,>=1.23.5 (from tensorflow==2.15.1)\n",
            "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.1) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.1) (24.2)\n",
            "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 (from tensorflow==2.15.1)\n",
            "  Downloading protobuf-4.25.8-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.1) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.1) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.1) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.1) (4.14.1)\n",
            "Collecting wrapt<1.15,>=1.11.0 (from tensorflow==2.15.1)\n",
            "  Downloading wrapt-1.14.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.1) (0.37.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.1) (1.73.1)\n",
            "Collecting tensorboard<2.16,>=2.15 (from tensorflow==2.15.1)\n",
            "  Downloading tensorboard-2.15.2-py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting tensorflow-estimator<2.16,>=2.15.0 (from tensorflow==2.15.1)\n",
            "  Downloading tensorflow_estimator-2.15.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting keras<2.16,>=2.15.0 (from tensorflow==2.15.1)\n",
            "  Downloading keras-2.15.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow==2.15.1) (0.45.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.1) (2.38.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.1) (1.2.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.1) (3.8.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.1) (2.32.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.1) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.1) (3.1.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.1) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.1) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.1) (4.9.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow==2.15.1) (2.0.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.1) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.1) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.1) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.1) (2025.7.14)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow==2.15.1) (3.0.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.1) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow==2.15.1) (3.3.1)\n",
            "Downloading tensorflow-2.15.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (475.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m475.3/475.3 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading keras-2.15.0-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m64.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ml_dtypes-0.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m79.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m93.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading protobuf-4.25.8-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.9/294.9 kB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard-2.15.2-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m107.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_estimator-2.15.0-py2.py3-none-any.whl (441 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m442.0/442.0 kB\u001b[0m \u001b[31m31.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wrapt-1.14.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.4/78.4 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: wrapt, tensorflow-estimator, protobuf, numpy, keras, ml-dtypes, tensorboard, tensorflow\n",
            "  Attempting uninstall: wrapt\n",
            "    Found existing installation: wrapt 1.17.2\n",
            "    Uninstalling wrapt-1.17.2:\n",
            "      Successfully uninstalled wrapt-1.17.2\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 5.29.5\n",
            "    Uninstalling protobuf-5.29.5:\n",
            "      Successfully uninstalled protobuf-5.29.5\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 3.8.0\n",
            "    Uninstalling keras-3.8.0:\n",
            "      Successfully uninstalled keras-3.8.0\n",
            "  Attempting uninstall: ml-dtypes\n",
            "    Found existing installation: ml-dtypes 0.4.1\n",
            "    Uninstalling ml-dtypes-0.4.1:\n",
            "      Successfully uninstalled ml-dtypes-0.4.1\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.18.0\n",
            "    Uninstalling tensorboard-2.18.0:\n",
            "      Successfully uninstalled tensorboard-2.18.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-text 2.18.1 requires tensorflow<2.19,>=2.18.0, but you have tensorflow 2.15.1 which is incompatible.\n",
            "grpcio-status 1.71.2 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 4.25.8 which is incompatible.\n",
            "tensorflow-decision-forests 1.11.0 requires tensorflow==2.18.0, but you have tensorflow 2.15.1 which is incompatible.\n",
            "tf-keras 2.18.0 requires tensorflow<2.19,>=2.18, but you have tensorflow 2.15.1 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n",
            "ydf 0.12.0 requires protobuf<6.0.0,>=5.29.1, but you have protobuf 4.25.8 which is incompatible.\n",
            "jax 0.5.2 requires ml_dtypes>=0.4.0, but you have ml-dtypes 0.3.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed keras-2.15.0 ml-dtypes-0.3.2 numpy-1.26.4 protobuf-4.25.8 tensorboard-2.15.2 tensorflow-2.15.1 tensorflow-estimator-2.15.0 wrapt-1.14.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google",
                  "numpy"
                ]
              },
              "id": "6ca5aacfc8c2456e8ea3fc1d0dccd12a"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will store the datasets we need in a google drive. So firstly, allow access to my google drive:"
      ],
      "metadata": {
        "id": "JwYqBFgmFTF9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "metadata": {
        "id": "l3zeGYoLYJx1",
        "outputId": "d3e4eef0-f137-4d2e-fe2b-fa20f0718495",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will also need a GPU to do the training, so check that one is enabled:"
      ],
      "metadata": {
        "id": "WAEq5hzlEWdP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "id": "J2Gh1YO3EVVe",
        "outputId": "07ed1c57-b0cd-48b8-cbac-99d105817c96"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SystemError",
          "evalue": "GPU device not found",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mSystemError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2-3825029784.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdevice_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgpu_device_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdevice_name\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'/device:GPU:0'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0;32mraise\u001b[0m \u001b[0mSystemError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'GPU device not found'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Found GPU at: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mSystemError\u001b[0m: GPU device not found"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Setup object detection API"
      ],
      "metadata": {
        "id": "WAyqIhrTBzA-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get access to the object detection API from a GitHub repository:"
      ],
      "metadata": {
        "id": "xY7hXBBEFR_v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pathlib\n",
        "\n",
        "if \"models\" in pathlib.Path.cwd().parts:\n",
        "  while \"models\" in pathlib.Path.cwd().parts:\n",
        "    os.chdir(\"..\")\n",
        "elif not pathlib.Path(\"models\").exists():\n",
        "  !git clone --depth 1 https://github.com/tensorflow/models"
      ],
      "metadata": {
        "id": "gFyA6aSnOWKt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47b74630-ed98-433e-acd1-70ecd095b801"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'models'...\n",
            "remote: Enumerating objects: 4355, done.\u001b[K\n",
            "remote: Counting objects: 100% (4355/4355), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3165/3165), done.\u001b[K\n",
            "remote: Total 4355 (delta 1188), reused 3994 (delta 1117), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (4355/4355), 69.96 MiB | 33.95 MiB/s, done.\n",
            "Resolving deltas: 100% (1188/1188), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "cd models/research/\n",
        "protoc object_detection/protos/*.proto --python_out=.\n",
        "cp object_detection/packages/tf2/setup.py .\n",
        "python -m pip install ."
      ],
      "metadata": {
        "id": "LX5j5d2gPFQK",
        "outputId": "ded809b5-2168-4d03-a7df-58207706f257",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing /content/models/research\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Collecting avro-python3 (from object_detection==0.1)\n",
            "  Downloading avro-python3-1.10.2.tar.gz (38 kB)\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Collecting apache-beam (from object_detection==0.1)\n",
            "  Downloading apache_beam-2.66.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from object_detection==0.1) (11.2.1)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from object_detection==0.1) (5.4.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from object_detection==0.1) (3.10.0)\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.11/dist-packages (from object_detection==0.1) (3.0.12)\n",
            "Collecting contextlib2 (from object_detection==0.1)\n",
            "  Downloading contextlib2-21.6.0-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tf-slim in /usr/local/lib/python3.11/dist-packages (from object_detection==0.1) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from object_detection==0.1) (1.17.0)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.11/dist-packages (from object_detection==0.1) (2.0.10)\n",
            "Collecting lvis (from object_detection==0.1)\n",
            "  Downloading lvis-0.5.3-py3-none-any.whl.metadata (856 bytes)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from object_detection==0.1) (1.15.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from object_detection==0.1) (2.2.2)\n",
            "Collecting tf-models-official>=2.5.1 (from object_detection==0.1)\n",
            "  Downloading tf_models_official-2.19.1-py2.py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting tensorflow_io (from object_detection==0.1)\n",
            "  Downloading tensorflow_io-0.37.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.11/dist-packages (from object_detection==0.1) (2.15.0)\n",
            "Collecting pyparsing==2.4.7 (from object_detection==0.1)\n",
            "  Downloading pyparsing-2.4.7-py2.py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting sacrebleu<=2.2.0 (from object_detection==0.1)\n",
            "  Downloading sacrebleu-2.2.0-py3-none-any.whl.metadata (55 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 55.4/55.4 kB 3.2 MB/s eta 0:00:00\n",
            "Collecting portalocker (from sacrebleu<=2.2.0->object_detection==0.1)\n",
            "  Downloading portalocker-3.2.0-py3-none-any.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from sacrebleu<=2.2.0->object_detection==0.1) (2024.11.6)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.11/dist-packages (from sacrebleu<=2.2.0->object_detection==0.1) (0.9.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from sacrebleu<=2.2.0->object_detection==0.1) (1.26.4)\n",
            "Collecting colorama (from sacrebleu<=2.2.0->object_detection==0.1)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: google-api-python-client>=1.6.7 in /usr/local/lib/python3.11/dist-packages (from tf-models-official>=2.5.1->object_detection==0.1) (2.176.0)\n",
            "Requirement already satisfied: kaggle>=1.3.9 in /usr/local/lib/python3.11/dist-packages (from tf-models-official>=2.5.1->object_detection==0.1) (1.7.4.5)\n",
            "Requirement already satisfied: oauth2client in /usr/local/lib/python3.11/dist-packages (from tf-models-official>=2.5.1->object_detection==0.1) (4.1.3)\n",
            "Requirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.11/dist-packages (from tf-models-official>=2.5.1->object_detection==0.1) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from tf-models-official>=2.5.1->object_detection==0.1) (9.0.0)\n",
            "Requirement already satisfied: tensorflow-hub>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from tf-models-official>=2.5.1->object_detection==0.1) (0.16.1)\n",
            "Collecting tensorflow-model-optimization>=0.4.1 (from tf-models-official>=2.5.1->object_detection==0.1)\n",
            "  Downloading tensorflow_model_optimization-0.8.0-py2.py3-none-any.whl.metadata (904 bytes)\n",
            "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.11/dist-packages (from tf-models-official>=2.5.1->object_detection==0.1) (4.9.9)\n",
            "Requirement already satisfied: tf-keras>=2.16.0 in /usr/local/lib/python3.11/dist-packages (from tf-models-official>=2.5.1->object_detection==0.1) (2.18.0)\n",
            "Requirement already satisfied: gin-config in /usr/local/lib/python3.11/dist-packages (from tf-models-official>=2.5.1->object_detection==0.1) (0.5.0)\n",
            "Requirement already satisfied: pyyaml>=6.0.0 in /usr/local/lib/python3.11/dist-packages (from tf-models-official>=2.5.1->object_detection==0.1) (6.0.2)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.11/dist-packages (from tf-models-official>=2.5.1->object_detection==0.1) (4.12.0.88)\n",
            "Collecting seqeval (from tf-models-official>=2.5.1->object_detection==0.1)\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 43.6/43.6 kB 3.5 MB/s eta 0:00:00\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from tf-models-official>=2.5.1->object_detection==0.1) (0.2.0)\n",
            "Requirement already satisfied: immutabledict in /usr/local/lib/python3.11/dist-packages (from tf-models-official>=2.5.1->object_detection==0.1) (4.2.1)\n",
            "Collecting ai-edge-litert>=1.0.1 (from tf-models-official>=2.5.1->object_detection==0.1)\n",
            "  Downloading ai_edge_litert-1.4.0-cp311-cp311-manylinux_2_17_x86_64.whl.metadata (1.9 kB)\n",
            "Collecting tensorflow~=2.19.0 (from tf-models-official>=2.5.1->object_detection==0.1)\n",
            "  Downloading tensorflow-2.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
            "Collecting tensorflow-text~=2.19.0 (from tf-models-official>=2.5.1->object_detection==0.1)\n",
            "  Downloading tensorflow_text-2.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->object_detection==0.1) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->object_detection==0.1) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->object_detection==0.1) (2025.2)\n",
            "Requirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.11/dist-packages (from tf-slim->object_detection==0.1) (1.4.0)\n",
            "Collecting crcmod<2.0,>=1.7 (from apache-beam->object_detection==0.1)\n",
            "  Downloading crcmod-1.7.tar.gz (89 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 89.7/89.7 kB 6.8 MB/s eta 0:00:00\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Requirement already satisfied: orjson<4,>=3.9.7 in /usr/local/lib/python3.11/dist-packages (from apache-beam->object_detection==0.1) (3.10.18)\n",
            "Collecting dill<0.3.2,>=0.3.1.1 (from apache-beam->object_detection==0.1)\n",
            "  Downloading dill-0.3.1.1.tar.gz (151 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 152.0/152.0 kB 12.5 MB/s eta 0:00:00\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Collecting fastavro<2,>=0.23.6 (from apache-beam->object_detection==0.1)\n",
            "  Downloading fastavro-1.11.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.7 kB)\n",
            "Collecting fasteners<1.0,>=0.3 (from apache-beam->object_detection==0.1)\n",
            "  Downloading fasteners-0.19-py3-none-any.whl.metadata (4.9 kB)\n",
            "Collecting grpcio!=1.48.0,!=1.59.*,!=1.60.*,!=1.61.*,!=1.62.0,!=1.62.1,<1.66.0,<2,>=1.33.1 (from apache-beam->object_detection==0.1)\n",
            "  Downloading grpcio-1.65.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.3 kB)\n",
            "Collecting hdfs<3.0.0,>=2.1.0 (from apache-beam->object_detection==0.1)\n",
            "  Downloading hdfs-2.7.3.tar.gz (43 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 43.5/43.5 kB 3.3 MB/s eta 0:00:00\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Requirement already satisfied: httplib2<0.23.0,>=0.8 in /usr/local/lib/python3.11/dist-packages (from apache-beam->object_detection==0.1) (0.22.0)\n",
            "Requirement already satisfied: jsonschema<5.0.0,>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from apache-beam->object_detection==0.1) (4.24.0)\n",
            "Collecting jsonpickle<4.0.0,>=3.0.0 (from apache-beam->object_detection==0.1)\n",
            "  Downloading jsonpickle-3.4.2-py3-none-any.whl.metadata (8.1 kB)\n",
            "Collecting objsize<0.8.0,>=0.6.1 (from apache-beam->object_detection==0.1)\n",
            "  Downloading objsize-0.7.1-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: packaging>=22.0 in /usr/local/lib/python3.11/dist-packages (from apache-beam->object_detection==0.1) (24.2)\n",
            "Collecting pymongo<5.0.0,>=3.8.0 (from apache-beam->object_detection==0.1)\n",
            "  Downloading pymongo-4.13.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (22 kB)\n",
            "Requirement already satisfied: proto-plus<2,>=1.7.1 in /usr/local/lib/python3.11/dist-packages (from apache-beam->object_detection==0.1) (1.26.1)\n",
            "Requirement already satisfied: protobuf!=4.0.*,!=4.21.*,!=4.22.0,!=4.23.*,!=4.24.*,<6.0.0.dev0,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from apache-beam->object_detection==0.1) (4.25.8)\n",
            "Collecting pydot<2,>=1.2.0 (from apache-beam->object_detection==0.1)\n",
            "  Downloading pydot-1.4.2-py2.py3-none-any.whl.metadata (8.0 kB)\n",
            "Collecting redis<6,>=5.0.0 (from apache-beam->object_detection==0.1)\n",
            "  Downloading redis-5.3.0-py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.24.0 in /usr/local/lib/python3.11/dist-packages (from apache-beam->object_detection==0.1) (2.32.3)\n",
            "Requirement already satisfied: sortedcontainers>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from apache-beam->object_detection==0.1) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.0 in /usr/local/lib/python3.11/dist-packages (from apache-beam->object_detection==0.1) (4.14.1)\n",
            "Requirement already satisfied: zstandard<1,>=0.18.0 in /usr/local/lib/python3.11/dist-packages (from apache-beam->object_detection==0.1) (0.23.0)\n",
            "Requirement already satisfied: pyarrow<19.0.0,>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from apache-beam->object_detection==0.1) (18.1.0)\n",
            "Collecting pyarrow-hotfix<1 (from apache-beam->object_detection==0.1)\n",
            "  Downloading pyarrow_hotfix-0.7-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: cycler>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from lvis->object_detection==0.1) (0.12.1)\n",
            "Requirement already satisfied: kiwisolver>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from lvis->object_detection==0.1) (1.4.8)\n",
            "Requirement already satisfied: opencv-python>=4.1.0.25 in /usr/local/lib/python3.11/dist-packages (from lvis->object_detection==0.1) (4.11.0.86)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->object_detection==0.1) (1.3.2)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->object_detection==0.1) (4.58.5)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem==0.37.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow_io->object_detection==0.1) (0.37.1)\n",
            "Collecting backports.strenum (from ai-edge-litert>=1.0.1->tf-models-official>=2.5.1->object_detection==0.1)\n",
            "  Downloading backports_strenum-1.2.8-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from ai-edge-litert>=1.0.1->tf-models-official>=2.5.1->object_detection==0.1) (25.2.10)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from ai-edge-litert>=1.0.1->tf-models-official>=2.5.1->object_detection==0.1) (4.67.1)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object_detection==0.1) (2.38.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object_detection==0.1) (0.2.0)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object_detection==0.1) (2.25.1)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object_detection==0.1) (4.2.0)\n",
            "Collecting docopt (from hdfs<3.0.0,>=2.1.0->apache-beam->object_detection==0.1)\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam->object_detection==0.1) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam->object_detection==0.1) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam->object_detection==0.1) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam->object_detection==0.1) (0.26.0)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.11/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object_detection==0.1) (6.2.0)\n",
            "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.11/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object_detection==0.1) (2025.7.14)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.11/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object_detection==0.1) (3.4.2)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object_detection==0.1) (3.10)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.11/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object_detection==0.1) (8.0.4)\n",
            "Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.11/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object_detection==0.1) (75.2.0)\n",
            "Requirement already satisfied: text-unidecode in /usr/local/lib/python3.11/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object_detection==0.1) (1.3)\n",
            "Requirement already satisfied: urllib3>=1.15.1 in /usr/local/lib/python3.11/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object_detection==0.1) (2.4.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object_detection==0.1) (0.5.1)\n",
            "Collecting dnspython<3.0.0,>=1.16.0 (from pymongo<5.0.0,>=3.8.0->apache-beam->object_detection==0.1)\n",
            "  Downloading dnspython-2.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting PyJWT~=2.9.0 (from redis<6,>=5.0.0->apache-beam->object_detection==0.1)\n",
            "  Downloading PyJWT-2.9.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow~=2.19.0->tf-models-official>=2.5.1->object_detection==0.1) (1.6.3)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow~=2.19.0->tf-models-official>=2.5.1->object_detection==0.1) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow~=2.19.0->tf-models-official>=2.5.1->object_detection==0.1) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow~=2.19.0->tf-models-official>=2.5.1->object_detection==0.1) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow~=2.19.0->tf-models-official>=2.5.1->object_detection==0.1) (3.4.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow~=2.19.0->tf-models-official>=2.5.1->object_detection==0.1) (3.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow~=2.19.0->tf-models-official>=2.5.1->object_detection==0.1) (1.14.1)\n",
            "Collecting tensorboard~=2.19.0 (from tensorflow~=2.19.0->tf-models-official>=2.5.1->object_detection==0.1)\n",
            "  Downloading tensorboard-2.19.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting keras (from object_detection==0.1)\n",
            "  Downloading keras-3.10.0-py3-none-any.whl.metadata (6.0 kB)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow~=2.19.0->tf-models-official>=2.5.1->object_detection==0.1) (3.14.0)\n",
            "Collecting ml-dtypes<1.0.0,>=0.5.1 (from tensorflow~=2.19.0->tf-models-official>=2.5.1->object_detection==0.1)\n",
            "  Downloading ml_dtypes-0.5.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (21 kB)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras->object_detection==0.1) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras->object_detection==0.1) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras->object_detection==0.1) (0.16.0)\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow-model-optimization>=0.4.1->tf-models-official>=2.5.1->object_detection==0.1) (0.1.9)\n",
            "INFO: pip is looking at multiple versions of tf-keras to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting tf-keras>=2.16.0 (from tf-models-official>=2.5.1->object_detection==0.1)\n",
            "  Downloading tf_keras-2.19.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.11/dist-packages (from oauth2client->tf-models-official>=2.5.1->object_detection==0.1) (0.6.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.11/dist-packages (from oauth2client->tf-models-official>=2.5.1->object_detection==0.1) (0.4.2)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from oauth2client->tf-models-official>=2.5.1->object_detection==0.1) (4.9.1)\n",
            "INFO: pip is looking at multiple versions of opencv-python-headless to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting opencv-python-headless (from tf-models-official>=2.5.1->object_detection==0.1)\n",
            "  Downloading opencv_python_headless-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras->object_detection==0.1) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras->object_detection==0.1) (2.19.2)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.11/dist-packages (from seqeval->tf-models-official>=2.5.1->object_detection==0.1) (1.6.1)\n",
            "Requirement already satisfied: array_record>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object_detection==0.1) (0.7.2)\n",
            "Requirement already satisfied: etils>=1.9.1 in /usr/local/lib/python3.11/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets->tf-models-official>=2.5.1->object_detection==0.1) (1.12.2)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object_detection==0.1) (2.3)\n",
            "Requirement already satisfied: simple_parsing in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object_detection==0.1) (0.1.7)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object_detection==0.1) (1.17.2)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object_detection==0.1) (0.10.2)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow~=2.19.0->tf-models-official>=2.5.1->object_detection==0.1) (0.45.1)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets->tf-models-official>=2.5.1->object_detection==0.1) (0.8.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets->tf-models-official>=2.5.1->object_detection==0.1) (2025.3.2)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.11/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets->tf-models-official>=2.5.1->object_detection==0.1) (6.5.2)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.11/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets->tf-models-official>=2.5.1->object_detection==0.1) (3.23.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object_detection==0.1) (1.70.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object_detection==0.1) (5.5.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras->object_detection==0.1) (0.1.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object_detection==0.1) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object_detection==0.1) (3.6.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard~=2.19.0->tensorflow~=2.19.0->tf-models-official>=2.5.1->object_detection==0.1) (3.8.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard~=2.19.0->tensorflow~=2.19.0->tf-models-official>=2.5.1->object_detection==0.1) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard~=2.19.0->tensorflow~=2.19.0->tf-models-official>=2.5.1->object_detection==0.1) (3.1.3)\n",
            "Requirement already satisfied: docstring-parser<1.0,>=0.15 in /usr/local/lib/python3.11/dist-packages (from simple_parsing->tensorflow-datasets->tf-models-official>=2.5.1->object_detection==0.1) (0.16)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow~=2.19.0->tf-models-official>=2.5.1->object_detection==0.1) (3.0.2)\n",
            "Downloading pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 67.8/67.8 kB 5.0 MB/s eta 0:00:00\n",
            "Downloading sacrebleu-2.2.0-py3-none-any.whl (116 kB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 116.6/116.6 kB 3.6 MB/s eta 0:00:00\n",
            "Downloading tf_models_official-2.19.1-py2.py3-none-any.whl (2.9 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.9/2.9 MB 23.8 MB/s eta 0:00:00\n",
            "Downloading apache_beam-2.66.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.4 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 17.4/17.4 MB 58.1 MB/s eta 0:00:00\n",
            "Downloading contextlib2-21.6.0-py2.py3-none-any.whl (13 kB)\n",
            "Downloading lvis-0.5.3-py3-none-any.whl (14 kB)\n",
            "Downloading tensorflow_io-0.37.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.6 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 49.6/49.6 MB 11.0 MB/s eta 0:00:00\n",
            "Downloading ai_edge_litert-1.4.0-cp311-cp311-manylinux_2_17_x86_64.whl (11.2 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 11.2/11.2 MB 35.7 MB/s eta 0:00:00\n",
            "Downloading fastavro-1.11.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.3/3.3 MB 33.0 MB/s eta 0:00:00\n",
            "Downloading fasteners-0.19-py3-none-any.whl (18 kB)\n",
            "Downloading grpcio-1.65.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.7 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.7/5.7 MB 27.9 MB/s eta 0:00:00\n",
            "Downloading jsonpickle-3.4.2-py3-none-any.whl (46 kB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 46.3/46.3 kB 3.6 MB/s eta 0:00:00\n",
            "Downloading objsize-0.7.1-py3-none-any.whl (11 kB)\n",
            "Downloading pyarrow_hotfix-0.7-py3-none-any.whl (7.9 kB)\n",
            "Downloading pydot-1.4.2-py2.py3-none-any.whl (21 kB)\n",
            "Downloading pymongo-4.13.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.4 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.4/1.4 MB 24.6 MB/s eta 0:00:00\n",
            "Downloading redis-5.3.0-py3-none-any.whl (272 kB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 272.8/272.8 kB 17.9 MB/s eta 0:00:00\n",
            "Downloading tensorflow-2.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (644.9 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 644.9/644.9 MB 612.0 kB/s eta 0:00:00\n",
            "Downloading keras-3.10.0-py3-none-any.whl (1.4 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.4/1.4 MB 4.1 MB/s eta 0:00:00\n",
            "Downloading ml_dtypes-0.5.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4.7/4.7 MB 6.6 MB/s eta 0:00:00\n",
            "Downloading tensorflow_model_optimization-0.8.0-py2.py3-none-any.whl (242 kB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 242.5/242.5 kB 5.7 MB/s eta 0:00:00\n",
            "Downloading tensorflow_text-2.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.2 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.2/5.2 MB 9.4 MB/s eta 0:00:00\n",
            "Downloading tf_keras-2.19.0-py3-none-any.whl (1.7 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.7/1.7 MB 10.7 MB/s eta 0:00:00\n",
            "Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Downloading opencv_python_headless-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (50.0 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 50.0/50.0 MB 9.4 MB/s eta 0:00:00\n",
            "Downloading portalocker-3.2.0-py3-none-any.whl (22 kB)\n",
            "Downloading dnspython-2.7.0-py3-none-any.whl (313 kB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 313.6/313.6 kB 12.4 MB/s eta 0:00:00\n",
            "Downloading PyJWT-2.9.0-py3-none-any.whl (22 kB)\n",
            "Downloading tensorboard-2.19.0-py3-none-any.whl (5.5 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.5/5.5 MB 19.7 MB/s eta 0:00:00\n",
            "Downloading backports_strenum-1.2.8-py3-none-any.whl (7.9 kB)\n",
            "Building wheels for collected packages: object_detection, avro-python3, crcmod, dill, hdfs, seqeval, docopt\n",
            "  Building wheel for object_detection (setup.py): started\n",
            "  Building wheel for object_detection (setup.py): finished with status 'done'\n",
            "  Created wheel for object_detection: filename=object_detection-0.1-py3-none-any.whl size=1697325 sha256=0d6877f52ea24efec25ad6ffe44cd0ead5af26b34f36d93768546393c210ee34\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-o1kvcv46/wheels/95/4a/63/b2d36ca06eab841de19a38993ffaf2beac152a44539bc642a6\n",
            "  Building wheel for avro-python3 (setup.py): started\n",
            "  Building wheel for avro-python3 (setup.py): finished with status 'done'\n",
            "  Created wheel for avro-python3: filename=avro_python3-1.10.2-py3-none-any.whl size=43993 sha256=696d77051ed01cbccc3af0e2d5bbdb4905ba882ff2ec1ed09a47fb99479826d1\n",
            "  Stored in directory: /root/.cache/pip/wheels/31/be/50/1145d9510eb4440893fc0ec676ef9464a05e0f7492a76fbb2c\n",
            "  Building wheel for crcmod (setup.py): started\n",
            "  Building wheel for crcmod (setup.py): finished with status 'done'\n",
            "  Created wheel for crcmod: filename=crcmod-1.7-cp311-cp311-linux_x86_64.whl size=31656 sha256=8fc150751ab9537922be0ba28d00284061dd30a8b54f1d4919c88b702cf84436\n",
            "  Stored in directory: /root/.cache/pip/wheels/23/94/7a/8cb7d14597e6395ce969933f01aed9ea8fa5f5b4d4c8a61e99\n",
            "  Building wheel for dill (setup.py): started\n",
            "  Building wheel for dill (setup.py): finished with status 'done'\n",
            "  Created wheel for dill: filename=dill-0.3.1.1-py3-none-any.whl size=78544 sha256=3ec86f24f06d06e11abc48e00e0c6c75dec522090c8bd334a017575d2abc6ff7\n",
            "  Stored in directory: /root/.cache/pip/wheels/01/60/80/1622338bcecce31a5664ef01c203cc5a7b09f59588d9c07376\n",
            "  Building wheel for hdfs (setup.py): started\n",
            "  Building wheel for hdfs (setup.py): finished with status 'done'\n",
            "  Created wheel for hdfs: filename=hdfs-2.7.3-py3-none-any.whl size=34324 sha256=c11a02a21989aca7ace8048ebe81cb6dd7be6de8ce3c4118771353ee530586aa\n",
            "  Stored in directory: /root/.cache/pip/wheels/b9/1d/dc/eb0833be25464c359903d356c4204721c6a672c26ff164cdc3\n",
            "  Building wheel for seqeval (setup.py): started\n",
            "  Building wheel for seqeval (setup.py): finished with status 'done'\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16162 sha256=97f4f59eb95a5945a852b2c1fa97207646013a870b7e6c7ca33b426bd97341dc\n",
            "  Stored in directory: /root/.cache/pip/wheels/bc/92/f0/243288f899c2eacdfa8c5f9aede4c71a9bad0ee26a01dc5ead\n",
            "  Building wheel for docopt (setup.py): started\n",
            "  Building wheel for docopt (setup.py): finished with status 'done'\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13706 sha256=345fee55db4e36f7f2a215cc35ba22e16ca64bcfbf997f520eb9eb56c5bf5bd0\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/b0/8c/4b75c4116c31f83c8f9f047231251e13cc74481cca4a78a9ce\n",
            "Successfully built object_detection avro-python3 crcmod dill hdfs seqeval docopt\n",
            "Installing collected packages: docopt, crcmod, tensorflow_io, pyparsing, PyJWT, pyarrow-hotfix, portalocker, opencv-python-headless, objsize, ml-dtypes, jsonpickle, grpcio, fasteners, fastavro, dnspython, dill, contextlib2, colorama, backports.strenum, avro-python3, tensorflow-model-optimization, tensorboard, sacrebleu, redis, pymongo, pydot, hdfs, ai-edge-litert, seqeval, lvis, keras, tensorflow, apache-beam, tf-keras, tensorflow-text, tf-models-official, object_detection\n",
            "  Attempting uninstall: pyparsing\n",
            "    Found existing installation: pyparsing 3.2.3\n",
            "    Uninstalling pyparsing-3.2.3:\n",
            "      Successfully uninstalled pyparsing-3.2.3\n",
            "  Attempting uninstall: PyJWT\n",
            "    Found existing installation: PyJWT 2.10.1\n",
            "    Uninstalling PyJWT-2.10.1:\n",
            "      Successfully uninstalled PyJWT-2.10.1\n",
            "  Attempting uninstall: opencv-python-headless\n",
            "    Found existing installation: opencv-python-headless 4.12.0.88\n",
            "    Uninstalling opencv-python-headless-4.12.0.88:\n",
            "      Successfully uninstalled opencv-python-headless-4.12.0.88\n",
            "  Attempting uninstall: ml-dtypes\n",
            "    Found existing installation: ml-dtypes 0.3.2\n",
            "    Uninstalling ml-dtypes-0.3.2:\n",
            "      Successfully uninstalled ml-dtypes-0.3.2\n",
            "  Attempting uninstall: jsonpickle\n",
            "    Found existing installation: jsonpickle 4.1.1\n",
            "    Uninstalling jsonpickle-4.1.1:\n",
            "      Successfully uninstalled jsonpickle-4.1.1\n",
            "  Attempting uninstall: grpcio\n",
            "    Found existing installation: grpcio 1.73.1\n",
            "    Uninstalling grpcio-1.73.1:\n",
            "      Successfully uninstalled grpcio-1.73.1\n",
            "  Attempting uninstall: dill\n",
            "    Found existing installation: dill 0.3.7\n",
            "    Uninstalling dill-0.3.7:\n",
            "      Successfully uninstalled dill-0.3.7\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.15.2\n",
            "    Uninstalling tensorboard-2.15.2:\n",
            "      Successfully uninstalled tensorboard-2.15.2\n",
            "  Attempting uninstall: pydot\n",
            "    Found existing installation: pydot 3.0.4\n",
            "    Uninstalling pydot-3.0.4:\n",
            "      Successfully uninstalled pydot-3.0.4\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.15.0\n",
            "    Uninstalling keras-2.15.0:\n",
            "      Successfully uninstalled keras-2.15.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.15.1\n",
            "    Uninstalling tensorflow-2.15.1:\n",
            "      Successfully uninstalled tensorflow-2.15.1\n",
            "  Attempting uninstall: tf-keras\n",
            "    Found existing installation: tf_keras 2.18.0\n",
            "    Uninstalling tf_keras-2.18.0:\n",
            "      Successfully uninstalled tf_keras-2.18.0\n",
            "  Attempting uninstall: tensorflow-text\n",
            "    Found existing installation: tensorflow-text 2.18.1\n",
            "    Uninstalling tensorflow-text-2.18.1:\n",
            "      Successfully uninstalled tensorflow-text-2.18.1\n",
            "Successfully installed PyJWT-2.9.0 ai-edge-litert-1.4.0 apache-beam-2.66.0 avro-python3-1.10.2 backports.strenum-1.2.8 colorama-0.4.6 contextlib2-21.6.0 crcmod-1.7 dill-0.3.1.1 dnspython-2.7.0 docopt-0.6.2 fastavro-1.11.1 fasteners-0.19 grpcio-1.65.5 hdfs-2.7.3 jsonpickle-3.4.2 keras-3.10.0 lvis-0.5.3 ml-dtypes-0.5.1 object_detection-0.1 objsize-0.7.1 opencv-python-headless-4.11.0.86 portalocker-3.2.0 pyarrow-hotfix-0.7 pydot-1.4.2 pymongo-4.13.2 pyparsing-2.4.7 redis-5.3.0 sacrebleu-2.2.0 seqeval-1.2.2 tensorboard-2.19.0 tensorflow-2.19.0 tensorflow-model-optimization-0.8.0 tensorflow-text-2.19.0 tensorflow_io-0.37.1 tf-keras-2.19.0 tf-models-official-2.19.1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "grpcio-status 1.71.2 requires grpcio>=1.71.2, but you have grpcio 1.65.5 which is incompatible.\n",
            "grpcio-status 1.71.2 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 4.25.8 which is incompatible.\n",
            "tensorflow-decision-forests 1.11.0 requires tensorflow==2.18.0, but you have tensorflow 2.19.0 which is incompatible.\n",
            "multiprocess 0.70.15 requires dill>=0.3.7, but you have dill 0.3.1.1 which is incompatible.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION'] = 'python'"
      ],
      "metadata": {
        "id": "3SbhghOuRDZg"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"TF_USE_LEGACY_KERAS\"] = \"1\""
      ],
      "metadata": {
        "id": "Z9khQ6gmdPnj"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run the model builder test to check whether installation succeeded:"
      ],
      "metadata": {
        "id": "5i2GHmuTQQC2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/models/research/object_detection/builders/model_builder_tf2_test.py"
      ],
      "metadata": {
        "id": "Zd_T_3P-P4_h",
        "outputId": "50074bfe-8b77-4710-d39c-de3adf71a151",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-07-17 16:23:49.012712: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1752769429.036343    3401 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1752769429.043216    3401 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1752769429.063359    3401 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1752769429.063405    3401 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1752769429.063412    3401 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1752769429.063415    3401 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "/usr/local/lib/python3.11/dist-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/usr/local/lib/python3.11/dist-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\n",
            "caused by: ['/usr/local/lib/python3.11/dist-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl5mutex6unlockEv']\n",
            "  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n",
            "/usr/local/lib/python3.11/dist-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/usr/local/lib/python3.11/dist-packages/tensorflow_io/python/ops/libtensorflow_io.so']\n",
            "caused by: ['/usr/local/lib/python3.11/dist-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZN3tsl7strings13safe_strtou64ESt17basic_string_viewIcSt11char_traitsIcEEPm']\n",
            "  warnings.warn(f\"file system plugins are not loaded: {e}\")\n",
            "2025-07-17 16:23:56.720452: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n",
            "Running tests under Python 3.11.13: /usr/bin/python3\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_deepmac\n",
            "WARNING:tensorflow:`tf.keras.layers.experimental.SyncBatchNormalization` endpoint is deprecated and will be removed in a future release. Please use `tf.keras.layers.BatchNormalization` with parameter `synchronized` set to True.\n",
            "W0717 16:23:56.779839 136718289489920 batch_normalization.py:1533] `tf.keras.layers.experimental.SyncBatchNormalization` endpoint is deprecated and will be removed in a future release. Please use `tf.keras.layers.BatchNormalization` with parameter `synchronized` set to True.\n",
            "W0717 16:23:57.150771 136718289489920 model_builder.py:1112] Building experimental DeepMAC meta-arch. Some features may be omitted.\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 0.91s\n",
            "I0717 16:23:57.636950 136718289489920 test_util.py:2634] time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 0.91s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_deepmac\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n",
            "[  FAILED  ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 0.01s\n",
            "I0717 16:23:57.646384 136718289489920 test_util.py:2634] time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 0.01s\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n",
            "[  FAILED  ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.0s\n",
            "I0717 16:23:57.649730 136718289489920 test_util.py:2634] time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.0s\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n",
            "[  FAILED  ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.0s\n",
            "I0717 16:23:57.652534 136718289489920 test_util.py:2634] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.0s\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n",
            "[  FAILED  ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 0.0s\n",
            "I0717 16:23:57.655192 136718289489920 test_util.py:2634] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 0.0s\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_experimental_model\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n",
            "I0717 16:23:57.655673 136718289489920 test_util.py:2634] time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_experimental_model\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.05s\n",
            "I0717 16:23:57.703176 136718289489920 test_util.py:2634] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.05s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.03s\n",
            "I0717 16:23:57.730740 136718289489920 test_util.py:2634] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.03s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.03s\n",
            "I0717 16:23:57.759004 136718289489920 test_util.py:2634] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.03s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.18s\n",
            "I0717 16:23:57.941908 136718289489920 test_util.py:2634] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.18s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.17s\n",
            "I0717 16:23:58.111645 136718289489920 test_util.py:2634] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.17s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.18s\n",
            "I0717 16:23:58.288180 136718289489920 test_util.py:2634] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.18s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.19s\n",
            "I0717 16:23:58.480114 136718289489920 test_util.py:2634] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.19s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.18s\n",
            "I0717 16:23:58.663460 136718289489920 test_util.py:2634] time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.18s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.05s\n",
            "I0717 16:23:58.716368 136718289489920 test_util.py:2634] time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.05s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n",
            "I0717 16:23:59.039679 136718289489920 ssd_efficientnet_bifpn_feature_extractor.py:161] EfficientDet EfficientNet backbone version: efficientnet-b0\n",
            "I0717 16:23:59.039864 136718289489920 ssd_efficientnet_bifpn_feature_extractor.py:163] EfficientDet BiFPN num filters: 64\n",
            "I0717 16:23:59.039939 136718289489920 ssd_efficientnet_bifpn_feature_extractor.py:164] EfficientDet BiFPN num iterations: 3\n",
            "I0717 16:23:59.047513 136718289489920 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I0717 16:23:59.111673 136718289489920 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I0717 16:23:59.111860 136718289489920 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I0717 16:23:59.281866 136718289489920 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I0717 16:23:59.282068 136718289489920 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I0717 16:23:59.694036 136718289489920 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I0717 16:23:59.694235 136718289489920 efficientnet_model.py:143] round_filter input=40 output=40\n",
            "I0717 16:24:00.147495 136718289489920 efficientnet_model.py:143] round_filter input=40 output=40\n",
            "I0717 16:24:00.147751 136718289489920 efficientnet_model.py:143] round_filter input=80 output=80\n",
            "I0717 16:24:00.825657 136718289489920 efficientnet_model.py:143] round_filter input=80 output=80\n",
            "I0717 16:24:00.825826 136718289489920 efficientnet_model.py:143] round_filter input=112 output=112\n",
            "I0717 16:24:01.340953 136718289489920 efficientnet_model.py:143] round_filter input=112 output=112\n",
            "I0717 16:24:01.341162 136718289489920 efficientnet_model.py:143] round_filter input=192 output=192\n",
            "I0717 16:24:02.003638 136718289489920 efficientnet_model.py:143] round_filter input=192 output=192\n",
            "I0717 16:24:02.003825 136718289489920 efficientnet_model.py:143] round_filter input=320 output=320\n",
            "I0717 16:24:02.171691 136718289489920 efficientnet_model.py:143] round_filter input=1280 output=1280\n",
            "I0717 16:24:02.280637 136718289489920 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.0, resolution=224, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0717 16:24:02.651066 136718289489920 ssd_efficientnet_bifpn_feature_extractor.py:161] EfficientDet EfficientNet backbone version: efficientnet-b1\n",
            "I0717 16:24:02.651242 136718289489920 ssd_efficientnet_bifpn_feature_extractor.py:163] EfficientDet BiFPN num filters: 88\n",
            "I0717 16:24:02.651324 136718289489920 ssd_efficientnet_bifpn_feature_extractor.py:164] EfficientDet BiFPN num iterations: 4\n",
            "I0717 16:24:02.653351 136718289489920 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I0717 16:24:02.680861 136718289489920 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I0717 16:24:02.681036 136718289489920 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I0717 16:24:02.907520 136718289489920 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I0717 16:24:02.907684 136718289489920 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I0717 16:24:03.334421 136718289489920 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I0717 16:24:03.334610 136718289489920 efficientnet_model.py:143] round_filter input=40 output=40\n",
            "I0717 16:24:03.744797 136718289489920 efficientnet_model.py:143] round_filter input=40 output=40\n",
            "I0717 16:24:03.744962 136718289489920 efficientnet_model.py:143] round_filter input=80 output=80\n",
            "I0717 16:24:04.303512 136718289489920 efficientnet_model.py:143] round_filter input=80 output=80\n",
            "I0717 16:24:04.303689 136718289489920 efficientnet_model.py:143] round_filter input=112 output=112\n",
            "I0717 16:24:04.866683 136718289489920 efficientnet_model.py:143] round_filter input=112 output=112\n",
            "I0717 16:24:04.866851 136718289489920 efficientnet_model.py:143] round_filter input=192 output=192\n",
            "I0717 16:24:05.620051 136718289489920 efficientnet_model.py:143] round_filter input=192 output=192\n",
            "I0717 16:24:05.620232 136718289489920 efficientnet_model.py:143] round_filter input=320 output=320\n",
            "I0717 16:24:05.954030 136718289489920 efficientnet_model.py:143] round_filter input=1280 output=1280\n",
            "I0717 16:24:06.026622 136718289489920 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.1, resolution=240, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0717 16:24:06.098050 136718289489920 ssd_efficientnet_bifpn_feature_extractor.py:161] EfficientDet EfficientNet backbone version: efficientnet-b2\n",
            "I0717 16:24:06.098232 136718289489920 ssd_efficientnet_bifpn_feature_extractor.py:163] EfficientDet BiFPN num filters: 112\n",
            "I0717 16:24:06.098307 136718289489920 ssd_efficientnet_bifpn_feature_extractor.py:164] EfficientDet BiFPN num iterations: 5\n",
            "I0717 16:24:06.100293 136718289489920 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I0717 16:24:06.126583 136718289489920 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I0717 16:24:06.126743 136718289489920 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I0717 16:24:06.334911 136718289489920 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I0717 16:24:06.335178 136718289489920 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I0717 16:24:06.732331 136718289489920 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I0717 16:24:06.732500 136718289489920 efficientnet_model.py:143] round_filter input=40 output=48\n",
            "I0717 16:24:07.159881 136718289489920 efficientnet_model.py:143] round_filter input=40 output=48\n",
            "I0717 16:24:07.160059 136718289489920 efficientnet_model.py:143] round_filter input=80 output=88\n",
            "I0717 16:24:07.776609 136718289489920 efficientnet_model.py:143] round_filter input=80 output=88\n",
            "I0717 16:24:07.776778 136718289489920 efficientnet_model.py:143] round_filter input=112 output=120\n",
            "I0717 16:24:08.382053 136718289489920 efficientnet_model.py:143] round_filter input=112 output=120\n",
            "I0717 16:24:08.382276 136718289489920 efficientnet_model.py:143] round_filter input=192 output=208\n",
            "I0717 16:24:09.198448 136718289489920 efficientnet_model.py:143] round_filter input=192 output=208\n",
            "I0717 16:24:09.198625 136718289489920 efficientnet_model.py:143] round_filter input=320 output=352\n",
            "I0717 16:24:09.577008 136718289489920 efficientnet_model.py:143] round_filter input=1280 output=1408\n",
            "I0717 16:24:09.660204 136718289489920 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.1, depth_coefficient=1.2, resolution=260, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0717 16:24:09.727843 136718289489920 ssd_efficientnet_bifpn_feature_extractor.py:161] EfficientDet EfficientNet backbone version: efficientnet-b3\n",
            "I0717 16:24:09.728008 136718289489920 ssd_efficientnet_bifpn_feature_extractor.py:163] EfficientDet BiFPN num filters: 160\n",
            "I0717 16:24:09.728114 136718289489920 ssd_efficientnet_bifpn_feature_extractor.py:164] EfficientDet BiFPN num iterations: 6\n",
            "I0717 16:24:09.730015 136718289489920 efficientnet_model.py:143] round_filter input=32 output=40\n",
            "I0717 16:24:09.760313 136718289489920 efficientnet_model.py:143] round_filter input=32 output=40\n",
            "I0717 16:24:09.760467 136718289489920 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I0717 16:24:09.979510 136718289489920 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I0717 16:24:09.979667 136718289489920 efficientnet_model.py:143] round_filter input=24 output=32\n",
            "I0717 16:24:10.420519 136718289489920 efficientnet_model.py:143] round_filter input=24 output=32\n",
            "I0717 16:24:10.420684 136718289489920 efficientnet_model.py:143] round_filter input=40 output=48\n",
            "I0717 16:24:10.824575 136718289489920 efficientnet_model.py:143] round_filter input=40 output=48\n",
            "I0717 16:24:10.824777 136718289489920 efficientnet_model.py:143] round_filter input=80 output=96\n",
            "I0717 16:24:11.845234 136718289489920 efficientnet_model.py:143] round_filter input=80 output=96\n",
            "I0717 16:24:11.845413 136718289489920 efficientnet_model.py:143] round_filter input=112 output=136\n",
            "I0717 16:24:12.916238 136718289489920 efficientnet_model.py:143] round_filter input=112 output=136\n",
            "I0717 16:24:12.916423 136718289489920 efficientnet_model.py:143] round_filter input=192 output=232\n",
            "I0717 16:24:14.396475 136718289489920 efficientnet_model.py:143] round_filter input=192 output=232\n",
            "I0717 16:24:14.396640 136718289489920 efficientnet_model.py:143] round_filter input=320 output=384\n",
            "I0717 16:24:14.919625 136718289489920 efficientnet_model.py:143] round_filter input=1280 output=1536\n",
            "I0717 16:24:15.003444 136718289489920 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.2, depth_coefficient=1.4, resolution=300, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0717 16:24:15.080030 136718289489920 ssd_efficientnet_bifpn_feature_extractor.py:161] EfficientDet EfficientNet backbone version: efficientnet-b4\n",
            "I0717 16:24:15.080192 136718289489920 ssd_efficientnet_bifpn_feature_extractor.py:163] EfficientDet BiFPN num filters: 224\n",
            "I0717 16:24:15.080272 136718289489920 ssd_efficientnet_bifpn_feature_extractor.py:164] EfficientDet BiFPN num iterations: 7\n",
            "I0717 16:24:15.082176 136718289489920 efficientnet_model.py:143] round_filter input=32 output=48\n",
            "I0717 16:24:15.112302 136718289489920 efficientnet_model.py:143] round_filter input=32 output=48\n",
            "I0717 16:24:15.112446 136718289489920 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I0717 16:24:15.338229 136718289489920 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I0717 16:24:15.338388 136718289489920 efficientnet_model.py:143] round_filter input=24 output=32\n",
            "I0717 16:24:15.888200 136718289489920 efficientnet_model.py:143] round_filter input=24 output=32\n",
            "I0717 16:24:15.888357 136718289489920 efficientnet_model.py:143] round_filter input=40 output=56\n",
            "I0717 16:24:16.962334 136718289489920 efficientnet_model.py:143] round_filter input=40 output=56\n",
            "I0717 16:24:16.962492 136718289489920 efficientnet_model.py:143] round_filter input=80 output=112\n",
            "I0717 16:24:17.951497 136718289489920 efficientnet_model.py:143] round_filter input=80 output=112\n",
            "I0717 16:24:17.951657 136718289489920 efficientnet_model.py:143] round_filter input=112 output=160\n",
            "I0717 16:24:18.907787 136718289489920 efficientnet_model.py:143] round_filter input=112 output=160\n",
            "I0717 16:24:18.907946 136718289489920 efficientnet_model.py:143] round_filter input=192 output=272\n",
            "I0717 16:24:20.335507 136718289489920 efficientnet_model.py:143] round_filter input=192 output=272\n",
            "I0717 16:24:20.335672 136718289489920 efficientnet_model.py:143] round_filter input=320 output=448\n",
            "I0717 16:24:20.741104 136718289489920 efficientnet_model.py:143] round_filter input=1280 output=1792\n",
            "I0717 16:24:20.836863 136718289489920 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.4, depth_coefficient=1.8, resolution=380, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0717 16:24:20.925794 136718289489920 ssd_efficientnet_bifpn_feature_extractor.py:161] EfficientDet EfficientNet backbone version: efficientnet-b5\n",
            "I0717 16:24:20.925955 136718289489920 ssd_efficientnet_bifpn_feature_extractor.py:163] EfficientDet BiFPN num filters: 288\n",
            "I0717 16:24:20.926035 136718289489920 ssd_efficientnet_bifpn_feature_extractor.py:164] EfficientDet BiFPN num iterations: 7\n",
            "I0717 16:24:20.927986 136718289489920 efficientnet_model.py:143] round_filter input=32 output=48\n",
            "I0717 16:24:20.953875 136718289489920 efficientnet_model.py:143] round_filter input=32 output=48\n",
            "I0717 16:24:20.954051 136718289489920 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I0717 16:24:21.291469 136718289489920 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I0717 16:24:21.291631 136718289489920 efficientnet_model.py:143] round_filter input=24 output=40\n",
            "I0717 16:24:21.989421 136718289489920 efficientnet_model.py:143] round_filter input=24 output=40\n",
            "I0717 16:24:21.989575 136718289489920 efficientnet_model.py:143] round_filter input=40 output=64\n",
            "I0717 16:24:22.736633 136718289489920 efficientnet_model.py:143] round_filter input=40 output=64\n",
            "I0717 16:24:22.736792 136718289489920 efficientnet_model.py:143] round_filter input=80 output=128\n",
            "I0717 16:24:23.805807 136718289489920 efficientnet_model.py:143] round_filter input=80 output=128\n",
            "I0717 16:24:23.805974 136718289489920 efficientnet_model.py:143] round_filter input=112 output=176\n",
            "I0717 16:24:24.979547 136718289489920 efficientnet_model.py:143] round_filter input=112 output=176\n",
            "I0717 16:24:24.979734 136718289489920 efficientnet_model.py:143] round_filter input=192 output=304\n",
            "I0717 16:24:27.335695 136718289489920 efficientnet_model.py:143] round_filter input=192 output=304\n",
            "I0717 16:24:27.335883 136718289489920 efficientnet_model.py:143] round_filter input=320 output=512\n",
            "I0717 16:24:28.386840 136718289489920 efficientnet_model.py:143] round_filter input=1280 output=2048\n",
            "I0717 16:24:28.556448 136718289489920 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.6, depth_coefficient=2.2, resolution=456, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0717 16:24:28.690284 136718289489920 ssd_efficientnet_bifpn_feature_extractor.py:161] EfficientDet EfficientNet backbone version: efficientnet-b6\n",
            "I0717 16:24:28.690438 136718289489920 ssd_efficientnet_bifpn_feature_extractor.py:163] EfficientDet BiFPN num filters: 384\n",
            "I0717 16:24:28.690511 136718289489920 ssd_efficientnet_bifpn_feature_extractor.py:164] EfficientDet BiFPN num iterations: 8\n",
            "I0717 16:24:28.692408 136718289489920 efficientnet_model.py:143] round_filter input=32 output=56\n",
            "I0717 16:24:28.724392 136718289489920 efficientnet_model.py:143] round_filter input=32 output=56\n",
            "I0717 16:24:28.724542 136718289489920 efficientnet_model.py:143] round_filter input=16 output=32\n",
            "I0717 16:24:29.069517 136718289489920 efficientnet_model.py:143] round_filter input=16 output=32\n",
            "I0717 16:24:29.069666 136718289489920 efficientnet_model.py:143] round_filter input=24 output=40\n",
            "I0717 16:24:29.883096 136718289489920 efficientnet_model.py:143] round_filter input=24 output=40\n",
            "I0717 16:24:29.883267 136718289489920 efficientnet_model.py:143] round_filter input=40 output=72\n",
            "I0717 16:24:30.766807 136718289489920 efficientnet_model.py:143] round_filter input=40 output=72\n",
            "I0717 16:24:30.766963 136718289489920 efficientnet_model.py:143] round_filter input=80 output=144\n",
            "I0717 16:24:32.042422 136718289489920 efficientnet_model.py:143] round_filter input=80 output=144\n",
            "I0717 16:24:32.042575 136718289489920 efficientnet_model.py:143] round_filter input=112 output=200\n",
            "I0717 16:24:33.895663 136718289489920 efficientnet_model.py:143] round_filter input=112 output=200\n",
            "I0717 16:24:33.895820 136718289489920 efficientnet_model.py:143] round_filter input=192 output=344\n",
            "I0717 16:24:36.004240 136718289489920 efficientnet_model.py:143] round_filter input=192 output=344\n",
            "I0717 16:24:36.004400 136718289489920 efficientnet_model.py:143] round_filter input=320 output=576\n",
            "I0717 16:24:36.742778 136718289489920 efficientnet_model.py:143] round_filter input=1280 output=2304\n",
            "I0717 16:24:36.871411 136718289489920 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.8, depth_coefficient=2.6, resolution=528, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0717 16:24:36.985258 136718289489920 ssd_efficientnet_bifpn_feature_extractor.py:161] EfficientDet EfficientNet backbone version: efficientnet-b7\n",
            "I0717 16:24:36.985408 136718289489920 ssd_efficientnet_bifpn_feature_extractor.py:163] EfficientDet BiFPN num filters: 384\n",
            "I0717 16:24:36.985480 136718289489920 ssd_efficientnet_bifpn_feature_extractor.py:164] EfficientDet BiFPN num iterations: 8\n",
            "I0717 16:24:36.987399 136718289489920 efficientnet_model.py:143] round_filter input=32 output=64\n",
            "I0717 16:24:37.017664 136718289489920 efficientnet_model.py:143] round_filter input=32 output=64\n",
            "I0717 16:24:37.017813 136718289489920 efficientnet_model.py:143] round_filter input=16 output=32\n",
            "I0717 16:24:37.462696 136718289489920 efficientnet_model.py:143] round_filter input=16 output=32\n",
            "I0717 16:24:37.462848 136718289489920 efficientnet_model.py:143] round_filter input=24 output=48\n",
            "I0717 16:24:38.474449 136718289489920 efficientnet_model.py:143] round_filter input=24 output=48\n",
            "I0717 16:24:38.474605 136718289489920 efficientnet_model.py:143] round_filter input=40 output=80\n",
            "I0717 16:24:39.833276 136718289489920 efficientnet_model.py:143] round_filter input=40 output=80\n",
            "I0717 16:24:39.833461 136718289489920 efficientnet_model.py:143] round_filter input=80 output=160\n",
            "I0717 16:24:42.093547 136718289489920 efficientnet_model.py:143] round_filter input=80 output=160\n",
            "I0717 16:24:42.093732 136718289489920 efficientnet_model.py:143] round_filter input=112 output=224\n",
            "I0717 16:24:43.873805 136718289489920 efficientnet_model.py:143] round_filter input=112 output=224\n",
            "I0717 16:24:43.873975 136718289489920 efficientnet_model.py:143] round_filter input=192 output=384\n",
            "I0717 16:24:46.522164 136718289489920 efficientnet_model.py:143] round_filter input=192 output=384\n",
            "I0717 16:24:46.522318 136718289489920 efficientnet_model.py:143] round_filter input=320 output=640\n",
            "I0717 16:24:47.654540 136718289489920 efficientnet_model.py:143] round_filter input=1280 output=2560\n",
            "I0717 16:24:47.778181 136718289489920 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=2.0, depth_coefficient=3.1, resolution=600, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 49.19s\n",
            "I0717 16:24:47.911602 136718289489920 test_util.py:2634] time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 49.19s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.02s\n",
            "I0717 16:24:48.129270 136718289489920 test_util.py:2634] time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.02s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n",
            "I0717 16:24:48.131849 136718289489920 test_util.py:2634] time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_model_config_proto\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n",
            "I0717 16:24:48.132507 136718289489920 test_util.py:2634] time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_model_config_proto\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n",
            "I0717 16:24:48.134258 136718289489920 test_util.py:2634] time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n",
            "[ RUN      ] ModelBuilderTF2Test.test_session\n",
            "[  SKIPPED ] ModelBuilderTF2Test.test_session\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n",
            "I0717 16:24:48.135562 136718289489920 test_util.py:2634] time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_meta_architecture\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n",
            "I0717 16:24:48.135974 136718289489920 test_util.py:2634] time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_meta_architecture\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n",
            "I0717 16:24:48.137047 136718289489920 test_util.py:2634] time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n",
            "======================================================================\n",
            "ERROR: test_create_center_net_model0 (customize_head_params=True) (__main__.ModelBuilderTF2Test)\n",
            "ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n",
            "test_create_center_net_model(customize_head_params=True)\n",
            "----------------------------------------------------------------------\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/absl/testing/parameterized.py\", line 318, in bound_param_test\n",
            "    return test_method(self, **testcase_params)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/models/research/object_detection/builders/model_builder_tf2_test.py\", line 295, in test_create_center_net_model\n",
            "    self.get_fake_keypoint_proto(\n",
            "  File \"/content/models/research/object_detection/builders/model_builder_tf2_test.py\", line 146, in get_fake_keypoint_proto\n",
            "    config = text_format.Merge(task_proto_txt,\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/protobuf/text_format.py\", line 721, in Merge\n",
            "    return MergeLines(\n",
            "           ^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/protobuf/text_format.py\", line 795, in MergeLines\n",
            "    return parser.MergeLines(lines, message)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/protobuf/text_format.py\", line 820, in MergeLines\n",
            "    self._ParseOrMerge(lines, message)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/protobuf/text_format.py\", line 844, in _ParseOrMerge\n",
            "    self._MergeField(tokenizer, message)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/protobuf/text_format.py\", line 981, in _MergeField\n",
            "    merger(tokenizer, message, field)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/protobuf/text_format.py\", line 1037, in _MergeMessageField\n",
            "    sub_message = getattr(message, field.name).GetEntryClass()()\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AttributeError: 'RepeatedCompositeFieldContainer' object has no attribute 'GetEntryClass'\n",
            "\n",
            "======================================================================\n",
            "ERROR: test_create_center_net_model1 (customize_head_params=False) (__main__.ModelBuilderTF2Test)\n",
            "ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n",
            "test_create_center_net_model(customize_head_params=False)\n",
            "----------------------------------------------------------------------\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/absl/testing/parameterized.py\", line 318, in bound_param_test\n",
            "    return test_method(self, **testcase_params)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/models/research/object_detection/builders/model_builder_tf2_test.py\", line 295, in test_create_center_net_model\n",
            "    self.get_fake_keypoint_proto(\n",
            "  File \"/content/models/research/object_detection/builders/model_builder_tf2_test.py\", line 146, in get_fake_keypoint_proto\n",
            "    config = text_format.Merge(task_proto_txt,\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/protobuf/text_format.py\", line 721, in Merge\n",
            "    return MergeLines(\n",
            "           ^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/protobuf/text_format.py\", line 795, in MergeLines\n",
            "    return parser.MergeLines(lines, message)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/protobuf/text_format.py\", line 820, in MergeLines\n",
            "    self._ParseOrMerge(lines, message)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/protobuf/text_format.py\", line 844, in _ParseOrMerge\n",
            "    self._MergeField(tokenizer, message)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/protobuf/text_format.py\", line 981, in _MergeField\n",
            "    merger(tokenizer, message, field)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/protobuf/text_format.py\", line 1037, in _MergeMessageField\n",
            "    sub_message = getattr(message, field.name).GetEntryClass()()\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AttributeError: 'RepeatedCompositeFieldContainer' object has no attribute 'GetEntryClass'\n",
            "\n",
            "======================================================================\n",
            "ERROR: test_create_center_net_model_from_keypoints (__main__.ModelBuilderTF2Test)\n",
            "ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n",
            "Test building a CenterNet model from proto txt.\n",
            "----------------------------------------------------------------------\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/models/research/object_detection/builders/model_builder_tf2_test.py\", line 452, in test_create_center_net_model_from_keypoints\n",
            "    self.get_fake_keypoint_proto())\n",
            "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/models/research/object_detection/builders/model_builder_tf2_test.py\", line 146, in get_fake_keypoint_proto\n",
            "    config = text_format.Merge(task_proto_txt,\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/protobuf/text_format.py\", line 721, in Merge\n",
            "    return MergeLines(\n",
            "           ^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/protobuf/text_format.py\", line 795, in MergeLines\n",
            "    return parser.MergeLines(lines, message)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/protobuf/text_format.py\", line 820, in MergeLines\n",
            "    self._ParseOrMerge(lines, message)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/protobuf/text_format.py\", line 844, in _ParseOrMerge\n",
            "    self._MergeField(tokenizer, message)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/protobuf/text_format.py\", line 981, in _MergeField\n",
            "    merger(tokenizer, message, field)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/protobuf/text_format.py\", line 1037, in _MergeMessageField\n",
            "    sub_message = getattr(message, field.name).GetEntryClass()()\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AttributeError: 'RepeatedCompositeFieldContainer' object has no attribute 'GetEntryClass'\n",
            "\n",
            "======================================================================\n",
            "ERROR: test_create_center_net_model_mobilenet (__main__.ModelBuilderTF2Test)\n",
            "ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n",
            "Test building a CenterNet model using bilinear interpolation.\n",
            "----------------------------------------------------------------------\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/models/research/object_detection/builders/model_builder_tf2_test.py\", line 497, in test_create_center_net_model_mobilenet\n",
            "    self.get_fake_keypoint_proto())\n",
            "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/models/research/object_detection/builders/model_builder_tf2_test.py\", line 146, in get_fake_keypoint_proto\n",
            "    config = text_format.Merge(task_proto_txt,\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/protobuf/text_format.py\", line 721, in Merge\n",
            "    return MergeLines(\n",
            "           ^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/protobuf/text_format.py\", line 795, in MergeLines\n",
            "    return parser.MergeLines(lines, message)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/protobuf/text_format.py\", line 820, in MergeLines\n",
            "    self._ParseOrMerge(lines, message)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/protobuf/text_format.py\", line 844, in _ParseOrMerge\n",
            "    self._MergeField(tokenizer, message)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/protobuf/text_format.py\", line 981, in _MergeField\n",
            "    merger(tokenizer, message, field)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/protobuf/text_format.py\", line 1037, in _MergeMessageField\n",
            "    sub_message = getattr(message, field.name).GetEntryClass()()\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AttributeError: 'RepeatedCompositeFieldContainer' object has no attribute 'GetEntryClass'\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "Ran 24 tests in 51.413s\n",
            "\n",
            "FAILED (errors=4, skipped=1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model builder test has failed, however all the errors are to do with Center Net models, which I do not intend to use. So we can proceed with the training process."
      ],
      "metadata": {
        "id": "OTrgW3n3hRmO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Start training"
      ],
      "metadata": {
        "id": "IJ3eUoVZBvq0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline_file = \"/content/drive/MyDrive/Object\\ Detection\\ Training/pre-trained-models/efficientdet_d4_coco17_tpu-32/pipeline.config\"\n",
        "model_dir = \"/content/drive/MyDrive/Object\\ Detection\\ Training/\""
      ],
      "metadata": {
        "id": "u8VR0CH6B86x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/models/research/object_detection/model_main_tf2.py \\\n",
        "    --pipeline_config_path={pipeline_file} \\\n",
        "    --model_dir={model_dir} \\"
      ],
      "metadata": {
        "id": "L3W_ciLHhvXR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}